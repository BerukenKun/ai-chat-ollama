ğŸ§  Chat de IA Local com Python + Ollama

Este projeto Ã© um pequeno chatbot que usa modelos de IA via Ollama.
O usuÃ¡rio digita mensagens e a IA responde em uma conversa contÃ­nua, com memÃ³ria de contexto.



ğŸš€ Tecnologias usadas

Python

Ollama

Llama 3.2 (modelo local)



ğŸ—‚ Como funciona

O usuÃ¡rio envia mensagens pelo terminal

O histÃ³rico Ã© salvo em history[]

O modelo recebe todo o contexto

A IA responde como um chat

A conversa continua atÃ© digitar sair



â–¶ï¸ Como rodar

Instalar o Ollama

Baixar o modelo:

ollama pull llama3.2



Instalar dependÃªncias:

pip install -r requirements.txt



Executar:

python main.py